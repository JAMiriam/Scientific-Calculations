\documentclass[11pt]{mk-polish-lab-report}

\usepackage{lipsum}
\usepackage[normalem]{ulem}
%\usepackage[light, math]{anttor}
\usepackage{array,multirow}

\usepackage{latexsym,amsmath,amssymb,amsthm}
\usepackage{multicol}
\renewcommand{\arraystretch}{1,25}
%\usepackage{amssymb}
\usepackage{breqn}
\usepackage{graphicx}
\usepackage{longtable} 

\let\times\relax% Set equal to \relax so that LaTeX thinks it's not defined
\DeclareMathOperator{\times}{\cdot}
\usepackage{subfig}
\graphicspath{ {plots/} }


%\sisetup{ exponent-product=\cdot}

\university{Politechnika Wrocławska}
\major{Informatyka, inż. I st.}
\tutor{dr hab. Paweł Zieliński}
\coursegroup{czwartek TN, 11:15}

\author{Miriam Jańczak}
\studentnumber{229761}
\title{Obliczenia naukowe}
\topic{Lista 3}


%% Uncomment to change margins size
%\geometry{top=2.5cm,bottom=2cm,left=2.5cm,right=2.5cm}

%% Uncomment to change vspace between items in lists
\setlist[enumerate]{itemsep=0pt}
%\setlist[itemize]{itemsep=0pt}
%\setlist[description]{itemsep=0pt}



\begin{document}

\maketitle

\section{Metoda bisekcji}

\subsection{Opis problemu}
Napisanie funkcji rozwiązującej równanie $f(x) = 0$ metodą bisekcji. Metoda bisekcji (połowienia przedziału) korzysta z własności Darboux dla funkcji ciągłej $f$. Mówi ona o tym, że jeżeli funkcja $f$ jest ciągła w przedziale $[a, b]$ i zmienia znak (tj. $f(a)f(b)<0$), to posiada ona zero w $(a, b)$. Schemat działania metody bisekcji jest następujący. Jeśli $f(a)f(b) < 0$, to obliczane jest $c = \frac{1}{2}(a + b)$ i sprawdzane czy $f(a)f(c) < 0$. Jeżeli tak, to $f$ ma zero w przedziale $[a, c]$, wtedy pod $b$ zostaje podstawione $c$. W przeciwnym razie zachodzi $f(c)f(b) < 0$, wtedy pod $a$ zostaje podstawione $c$. W ten sposób powstaje nowy przedział $[a, b]$, który jest dwa razy krótszy i zawiera zero funkcji $f$. Można więc na nim ponownie zastosować powyższe operacje. Warto zauważyć, że zastosowanie takiego schematu prowadzi do znalezienia nie wszystkich, lecz jednego zera funkcji $f$. Oczywiście, w momencie kiedy $f(a)f(c) = 0$, to $f(c) = 0$ i miejsce zerowe $f$ zostało znalezione. W praktyce jednak, pojawiają się błędy zaokrągleń i otrzymanie $f(c) = 0$ jest mało prawdopodobne, dlatego za kryterium zakończenia obliczeń należy przyjąć wartość odpowiednio bliską zeru w danej arytmetyce. 

\subsection{Rozwiązanie}
Działanie metody bisekcji przedstawia \Cref{alg:bis}.

\begin{algorithm}[!h]
\caption{Metoda bisekcji}
\label{alg:bis}
\DontPrintSemicolon
\SetKwFunction{proc}{mbisekcji}
\SetKwProg{myproc}{}{}{}
\myproc{\proc{f, a, b, delta, epsilon}}{
$u \leftarrow f(a)$\;
$v \leftarrow f(b)$\;
$e \leftarrow b - a$\;
$it \leftarrow 0$\;
\If {\texttt{sign}$(u) = $\texttt{sign}$(v)$}{
	\Return $err$ $1$\;
}
\While {$e > epsilon$}{
	$it \leftarrow it + 1$\;
	$e \leftarrow e / 2$\;
	$c \leftarrow a + e$\;
	$w \leftarrow f(c)$\;
	\If {$|e| < delta$ \textbf{or} $|w| < epsilon$}{
		\Return $c, w, it, 0$\;
	}
	\If {\texttt{sign}$(w) \neq $\texttt{sign}$(u)$}{
		$b \leftarrow c$\;
		$v \leftarrow w$\;
	}
	\Else {
		$a \leftarrow c$\;
		$u \leftarrow w$\;	
	}
}
}
\end{algorithm}

\begin{longtable}[l]{r  c  l}
%\begin{table}[!h]
%\centering
%\begin{tabular}{r  c  l}
\multicolumn{1}{l}{\textbf{Dane:}}&& \\
\texttt{f}&--&funkcja $f(x)$ zadana jako anonimowa funkcja (ang. anonymous function), \\
\texttt{a, b}&--&końce przedziału początkowego, \\
\texttt{delta, epsilon}&--&dokładności obliczeń, \\
&& \\
\multicolumn{1}{l}{\textbf{Wyniki:}}&& \\
\texttt{(r,v,it,err)}&--&czwórka, gdzie \\
\texttt{r}&--&przybliżenie pierwiastka równania $f(x) = 0$, \\
\texttt{v}&--&wartość $f(r)$, \\
\texttt{it}&--&liczba wykonanych iteracji, \\
\texttt{err}&--&sygnalizacja błędu \\
&&$0$ - brak błędu \\
&&$1$ - funkcja nie zmienia znaku w przedziale [a,b] \\
%\end{tabular}
\end{longtable}


\noindent Warto zauważyć tutaj kilka rzeczy. Po pierwsze, punkt środkowy $c$ obliczany jest za pomocą instrukcji $c \leftarrow a + (b - a)/2$, co jest lepsze z numerycznego punktu widzenia (dodanie do poprzedniej wartości drobnej poprawki). Wykonanie instrukcji $c \leftarrow (a + b)/2$ mogłoby spowodować, że w ekstremalnych przypadkach punkt $c$ znalazłby się poza przedziałem $[a, b]$. Po drugie, aby pozbyć się zbędnego mnożenia przy sprawdzeniu $f(a)f(c) < 0$, które mogłoby spowodować nadmiar lub niedomiar, zmianę znaku funkcji zbadano za pomocą nierówności $sign(w) \neq sign(u)$. Po trzecie, program uwzględnia trzy warunki zakończenia obliczeń. Warunek $e > epsilon$ mówi o tym, kiedy jeszcze jest możliwa iteracja w danym przedziale. Oprócz tego obliczenia są przerywane kiedy błąd jest dostatecznie mały ($abs(e) < delta$) lub gdy $f(c)$ jest dostatecznie bliskie zeru ($abs(w) < epsilon$).

\section{Metoda Newtona}

\subsection{Opis problemu}
Napisanie funkcji rozwiązującej równanie $f(x) = 0$ metodą Newtona. Metoda Newtona (stycznych) znajdująca zera funkcji opiera się na \emph{linearyzacji funkcji}, tj. zastąpieniu $f$ funkcją liniową. Jest nią suma dwóch początkowych składników we wzorze Taylora dla $f$. Zazwyczaj metoda Newtona jest szybsza od metod bisekcji i siecznych, gdyż jest zbieżność jest kwadratowa. W momencie gdy przybliżenia tworzone metodą Newtona są dostatecznie bliskie pierwiastka, staje się ona tak szybko zbieżna, że kilka przybliżeń pozwala osiągnąć maksymalną dokładność. Wadą tej metody jest jednak to, że nie zawsze jest zbieżna, dlatego często stosuje się ją w kombinacji z jakąś wolniejszą metodą, która jest już zbieżna globalnie. Inną wadą może być również konieczność liczenia pochodnej funkcji.
\subsection{Rozwiązanie}
Działanie metody Newtona przedstawia \Cref{alg:new}.
\begin{algorithm}[!h]
\caption{Metoda Newtona}
\label{alg:new}
\DontPrintSemicolon
\SetKwFunction{proc}{mstycznych}
\SetKwProg{myproc}{}{}{}
\myproc{\proc{f, $p_f$, $x_0$, delta, epsilon, maxit}}{
$v \leftarrow f(x_0)$\;

\If {$|v| < epsilon$}{
	\Return $x_0, v, 0, 0$\;
}

\If {$|p_f(x_0)| < epsilon$}{
	\Return $err$ $2$\;
}

\For {$it \leftarrow 1$ \KwTo $maxit$}{
	$x_1 \leftarrow x_0 - (v/p_f(x_0))$\;
	$v \leftarrow f(x_1)$\;
	\If {$|x_1 - x_0| < delta$ \textbf{or} $|v| < epsilon$}{
		\Return $x_1, v, it, 0$\;
	}
	$x_0 \leftarrow x_1$\;
}
\Return $err$ $1$\;
}
\end{algorithm} 
\begin{longtable}[l]{r  c  l}
%\begin{table}[!h]
%\centering
%\begin{tabular}{r  c  l}
\multicolumn{1}{l}{\textbf{Dane:}}&& \\
\texttt{f, pf}&--&funkcja $f(x)$ oraz pochodna $f'(x)$ zadane jako anonimowe funkcje, \\
\texttt{x0}&--&przybliżenie początkowe, \\
\texttt{delta, epsilon}&--&dokładności obliczeń, \\
\texttt{maxit}&--&maksymalna dopuszczalna liczba iteracji, \\
&& \\
\multicolumn{1}{l}{\textbf{Wyniki:}}&& \\
\texttt{(r,v,it,err)}&--&czwórka, gdzie \\
\texttt{r}&--&przybliżenie pierwiastka równania $f(x) = 0$, \\
\texttt{v}&--&wartość $f(r)$, \\
\texttt{it}&--&liczba wykonanych iteracji, \\
\texttt{err}&--&sygnalizacja błędu \\
&&$0$ - metoda zbieżna \\
&&$1$ - nie osiągnięto wymaganej dokładności w \texttt{maxit} iteracji \\
&&$2$ - pochodna bliska zeru \\
%\end{tabular}
\end{longtable}

\noindent Na początku działania algorytmu sprawdzane są warunki natychmiastowego zakończenia, gdy wartość funkcji dla przybliżenia początkowego jest dostatecznie bliska zeru - zwracany jest wynik oraz kiedy pochodna jest bliska zeru - niemożliwe jest wtedy zastosowanie metody. Następnie dla zadanej maksymalnej liczby iteracji wyznaczane są kolejne przybliżenia zera funkcji, które są dane rekurencyjnym wzorem $x_{n+1} := x_n - \dfrac{f(x_n)}{f'(x_n)}$ wynikającym bezpośrednio z definicji metody. Obliczenia są kończone kiedy znalezione zero mieści się w dokładności, bądź też odległość kolejnych przybliżeń jest dostatecznie mała. W przypadku nieotrzymania wyniku w zadanej liczbie iteracji zwracany jest błąd.

\section{Metoda siecznych}

\subsection{Opis problemu}
Napisanie funkcji rozwiązującej równanie $f(x) = 0$ metodą siecznych. Metoda siecznych wywodzi się bezpośrednio z metody Newtona, dla której starano się się uniknąć kłopotliwego wyliczania pochodnej funkcji. W tym celu $f'(x)$ zastąpiono ilorazem różnicowym -- $f'(x) \approx \dfrac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}$. Ta równość, wynikająca z definicji pochodnej daje właśnie metodę siecznych opisaną wzorem $x_{n+1} := x_n - f(x_n)\dfrac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}$. Zauważyć można, że $x_{n+1}$ wyrażone jest przez $x_n$ oraz $x_{n-1}$, dlatego potrzebne są dwa punkty początkowe, jednak każde nowe $x_{n+1}$ wymaga już tylko obliczenia jednej nowej wartości funkcji $f$. Metoda siecznych jest wolniej zbieżna od metody Newtona, jednak każdy krok tej metody wymaga obliczenia tylko jednej wartości funkcji, zaś w metodzie Newtona trzeba obliczyć dwie takie wartości, mianowicie $f(x)$ i $f'(x)$. W obu metodach najbardziej kosztowne jest obliczanie właśnie tych wartości i w tym sensie para kroków metody siecznych jest porównywalna z jednym krokiem metody Newtona.

\subsection{Rozwiązanie}
Działanie metody siecznych przedstawia \Cref{alg:sie}.
\begin{algorithm}[!h]
\caption{Metoda siecznych}
\label{alg:sie}
\DontPrintSemicolon
\SetKwFunction{proc}{msiecznych}
\SetKwProg{myproc}{}{}{}
\myproc{\proc{f, $x_0$, $x_1$, delta, epsilon, maxit}}{
$f_{x_0} \leftarrow f(x_0)$\;
$f_{x_1} \leftarrow f(x_1)$\;

\For {$it \leftarrow 1$ \KwTo $maxit$}{
	\If {$|f_{x_0}| > |f_{x_1}|$}{
		$x_0 \leftrightarrow x_1$\;
		$f_{x_0} \leftrightarrow f_{x_1}$\;
	}
	$s \leftarrow (x_1 - x_0)/(f_{x_1} - f_{x_0})$\;
	$x_1 \leftarrow x_0$\;
	$f_{x_1} \leftarrow f_{x_0}$\;
	$x_0 \leftarrow x_0 - (f_{x_0} \times s)$\;
	$f_{x_0} \leftarrow f(x_0)$\;
	\If {$|x_1 - x_0| < delta$ \textbf{or} $|f_{x_0}| < epsilon$}{
		\Return $x_0, f_{x_0}, it, 0$\;
	}
}
\Return $err$ $1$\;
}
\end{algorithm}
\begin{longtable}[l]{r  c  l}
%\begin{table}[!h]
%\centering
%\begin{tabular}{r  c  l}
\multicolumn{1}{l}{\textbf{Dane:}}&& \\
\texttt{f}&--&funkcja $f(x)$ zadana jako anonimowa funkcja, \\
\texttt{x0, x1}&--&przybliżenia początkowe, \\
\texttt{delta, epsilon}&--&dokładności obliczeń, \\
\texttt{maxit}&--&maksymalna dopuszczalna liczba iteracji, \\
&& \\
\multicolumn{1}{l}{\textbf{Wyniki:}}&& \\
\texttt{(r,v,it,err)}&--&czwórka, gdzie \\
\texttt{r}&--&przybliżenie pierwiastka równania $f(x) = 0$, \\
\texttt{v}&--&wartość $f(r)$, \\
\texttt{it}&--&liczba wykonanych iteracji, \\
\texttt{err}&--&sygnalizacja błędu \\
&&$0$ - metoda zbieżna \\
&&$1$ - nie osiągnięto wymaganej dokładności w \texttt{maxit} iteracji \\
%\end{tabular}
\end{longtable}
W algorytmie zastosowano metodę siecznych w której kolejne wartości funkcji mają nierosnące moduły. Przestawia on wartości $x_0$ i $x_1$, kiedy wymaga tego utrzymanie nierówności $|f_{x_0}| \leq |f_{x_1}|$. Algorytm kończy obliczenia $x_{n+1} := x_n - f(x_n)\dfrac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}$, kiedy znalezione zero mieści się w dokładności, bądź też odległość kolejnych przybliżeń jest dostatecznie mała. W przypadku nieotrzymania wyniku w zadanej liczbie iteracji zwracany jest błąd.

\section{Wyznaczanie pierwiastka równania $\sin{x}-(\frac{1}{2}x)^2 = 0$}

\subsection{Opis problemu}
Wyznaczanie pierwiastka równania $\sin{x} = -(\frac{1}{2}x)^2$ z użyciem metod:
\begin{enumerate}[(i)]
\item bisekcji (na przedziale początkowym $[1.5, 2.0]$),
\item Newtona (dla przybliżenia początkowego $x_0 = 1.5$),  
\item siecznych (dla przybliżeń początkowych $x_0 = 1.0, x_1 = 2.0$).
\end{enumerate}
Dla wszystkich metod zastosowano parametry dokładności $\delta = \frac{1}{2}10^{-5}$ oraz $\epsilon = \frac{1}{2}10^{-5}$.

\subsection{Rozwiązanie}
Zaimplementowano funkcję $f(x) = \sin{x}-(\frac{1}{2}x)^2$ oraz jej pochodną $f'(x) = \cos{x} - \frac{1}{2}x$ (potrzebną do poprawnego działania metody Newtona) i za pomocą metod stworzonych w zadaniach 1 -- 3 znaleziono szukane miejsca zerowe. Za maksymalną dopuszczalną liczbę iteracji przyjęto $32$.

\subsection{Wyniki}

Wyniki działania metod przedstawia \Cref{table:1}.

\begin{table}[h]
        \centering
        \footnotesize
\begin{tabular}{c
		|S[
        table-number-alignment = right,
		table-figures-integer  = 1,
		table-figures-decimal = 16
		]
		|S[
        table-number-alignment = right,
		table-figures-integer  = 2,
		table-figures-decimal = 16,
		table-figures-exponent = 2
		]|c|c}
Metoda& {Miejsce zerowe ($x_0$)} & {Wartość funkcji ($f(x_0)$)} & Liczba iteracji & Błąd \\ \hline
Bisekcji &1.9337539672851562&-2.7027680138402843e-7& 16 & 0 \\ 
Newtona &1.933753779789742&-2.2423316314856834e-8& 4 & 0 \\ 
Siecznych &1.9337539405015145&-2.3487103129049558e-7& 5 & 0 \\ 
\end{tabular}
\caption{Miejsca zerowe funkcji $f(x) = \sin{x}-(\frac{1}{2}x)^2$ obliczone za pomocą danych metod.}
\label{table:1}
\end{table}	

\subsection{Wnioski}
Powyższy przykład dobrze ukazuje różnicę w liczbie wykonanych iteracji dla poszczególnych metod. Metoda bisekcji potrzebowała aż szesnastu iteracji żeby znaleźć miejsce zerowe z podaną dokładnością, z kolei metoda Newtona i siecznych odpowiednio czterech i pięciu. Takie wyniki odzwierciedlają teoretyczną zbieżność tych metod. Metoda bisekcji posiada bowiem zbieżność liniową, metoda Newtona ma kwadratowy współczynnik zbieżności, a metoda siecznych zbiega nadliniowo ($\approx 1.62$). Analizując dane mogłoby się zdawać, że metoda bisekcji jest nie tylko metodą najwolniejszą, ale i najmniej dokładną, co jednak jest zbyt śmiałym wnioskiem. Bardziej można powiedzieć, że jest ,,najstabilniejsza'' ze wszystkich metod, znalazła bowiem ona wartość nie tyle najbliższą zeru, co wskazanej dokładności (niewątpliwą zaletą jest również to, że jest ona zbieżna globalnie i o ile końce przedziału początkowego faktycznie będą miały różne znaki to zawsze zbiegnie do zera funkcji). Dzięki temu, że metody Newtona i siecznych zbiegały szybciej niż metoda bisekcji w tym wypadku osiągnęły większą dokładność i ostatecznie znalazły się bliżej rzeczywistego zera, jednak dla innych funkcji, czy choćby inaczej dobranych przedziałów, okaże się że nie zawsze tak jest.

\section{Punkt przecięcia wykresów funkcji $y = 3x$ i $y = e^x$}

\subsection{Opis problemu}
Znalezienie, przy użyciu metody bisekcji, wartości zmiennej $x$, dla której przecinają się wykresy funkcji $y=3x$ oraz $y=e^x$.

\subsection{Rozwiązanie}
Łatwo zauważyć, że problem sprowadza się do rozwiązania równania $e^x - 3x = 0$, czyli znalezienia miejsc zerowych funkcji $f(x) = e^x - 3x$. W tym celu zaimplementowana została funkcja $f$, a także skorzystano z metody bisekcji stworzonej w zadaniu pierwszym. Jako dokładności obliczeń przyjęte zostały zadane $\delta = 10^{-4}$ oraz $\epsilon = 10^{-4}$. Przedziały początkowe wyznaczono w sposób eksperymentalny oparty na oszacowaniu wartości funkcji. W tym celu posłużono się wykresem przedstawionym na rysunku \ref{fig:zad51}. Zostały wybrane przedziały $[0, 1]$ oraz $[1, 2]$.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{zad51}\hfill
\caption{Wykresy funkcji $3x$ oraz $e^x$ wykonane w programie \emph{Wolfram Alpha}} \label{fig:zad51}
\end{figure} 

\subsection{Wyniki}
Otrzymane rozwiązania prezentuje \Cref{table:2}. Znalezione punkty przecięcia to $0.619140625$ i $1.5120849609375$.

\begin{table}[h]
        \centering
        \footnotesize
\begin{tabular}{c|c|c}
& $x_0$ & $x_1$ \\ \hline
Przedział & $[0, 1]$ & $[1, 2]$ \\ 
Wartość & $0.619140625$ & $1.5120849609375$ \\ 
Niedokładność $|f(x_i)|$ & $9.066320343276146 \times 10^{-5}$ & $7.618578602741621 \times 10^{-5}$ \\
Liczba iteracji &$9$&$13$ \\
\end{tabular}
\caption{Miejsca zerowe funkcji $f(x) = e^x - 3x$ obliczone za pomocą metody bisekcji.}
\label{table:2}
\end{table}	

\subsection{Wnioski}
Głównym problemem w wyznaczeniu punktów przecięcia się wykresów funkcji $y=3x$ i $y=e^x$ metodą bisekcji jest wybór przedziałów początkowych. Posiadając pewne umiejętności analityczne można spodziewać się obecności dwóch takich punktów w stosunkowo niewielkiej odległości od zera. Ciężej jednak szybko stwierdzić gdzie dokładnie należałoby odpowiednich przedziałów szukać. Uwagę zwraca fakt, że długość wybranych przedziałów jest niewielka, co może świadczyć o tym że do ich znalezienia była potrzebna dość dobra znajomość przebiegu funkcji $f(x) = e^x - 3x$ lub co najmniej kilka eksperymentów. W tym wypadku posłużono się wykresem, jednak ciężej byłoby znaleźć odpowiednie przedziały gdyby takiego narzędzia zabrakło. Kandydatem na przedział początkowy mógłby być przecież np. $[0, 2]$, na którego końcach funkcja nie zmienia znaku. Można jednak zauważyć, że przy rozsądnie dobranych przybliżeniach początkowych znajomość w miarę ogólnego przebiegu funkcji $f$ pozwala dużo łatwiej zastosować metodę siecznych czy metodę Newtona, które w tym wypadku okazują się zbieżne.

\section{Miejsce zerowe funkcji $f_1(x) = e^{1-x} - 1$ i $f_2(x) = xe^{-x}$}

\subsection{Opis problemu}
Znalezienie pierwiastków funkcji $f_1(x)=e^{1-x}-1$ oraz $f_2(x)=xe^{-x}$ przy pomocy metod bisekcji, stycznych oraz siecznych z dokładnością obliczeń $\delta=10^{-5}$ oraz $\epsilon=10^{-5}$.

\subsection{Rozwiązanie}
Zaimplementowano podane funkcje oraz wyliczono ich pochodne (potrzebne w metodzie Newtona). W celu znalezienia pierwiastków zostały wykorzystane metody stworzone w zadaniach 1 -- 3. Przeprowadzona została analiza funkcji $f_1$ i $f_2$, które zostały przedstawione na wykresie \ref{fig:zad61}. Na tej podstawie wybrano odpowiednie parametry mające na celu ukazanie właściwości poszczególnych metod oraz przykładów ich złego stosowania.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{zad6}\hfill
\caption{Wykresy funkcji $f(x)=e^{1-x}-1$ oraz $g(x)=xe^{-x}$ wykonane w programie \emph{Wolfram Alpha}} \label{fig:zad61}
\end{figure} 

\subsection{Wyniki}
Podczas analizy równania funkcji $f_1$ i $f_2$ niemal natychmiast nasuwają się poprawne rozwiązania -- $1$ dla $f_1$ oraz $0$ dla $f_2$. Większą uwagę poświęcono jednak pewnym eksperymentom związanym z zastosowaniem metod, niż uzyskaniu tylko poprawnych wyników, i tak \Cref{table:3} zawiera wyniki działania metody bisekcji dla różnych przedziałów początkowych, \Cref{table:4} wyniki uzyskane za pomocą metody Newtona dla różnych przybliżeń początkowych $x_0$ i wreszcie \Cref{table:5} wyniki metody siecznych dla różnych przybliżeń $x_0$ i $x_1$.

\begin{table}[h]
        \centering
        \footnotesize
\begin{tabular}{c
		|S[
        table-number-alignment = right,
		table-figures-integer  = 3,
		table-figures-decimal = 12,
		table-figures-exponent = 3
		]
		|S[
        table-number-alignment = right,
		table-figures-integer  = 2,
		table-figures-decimal = 15,
		table-figures-exponent = 3
		]|c}
Przedział& {$r$} & {$f(r)$} & Liczba iteracji \\ \hline
\multicolumn{4}{c}{$f_1$} \\ \hline
$[0.0,1.5]$&1.0000076293945312&-7.6293654275305656e-6&16 \\
$[0.5,3.0]$&0.9999923706054688&7.629423635080457e-6&16 \\
$[-4.0,4.0]$&1.0&0.0&3 \\
$[0.0,100.0]$&0.9999990463256836&9.536747711536009e-7&22 \\
$[-10.0,2000.0]$&1.0000018030405045&-1.803038878978036e-6&27 \\ \hline
\multicolumn{4}{c}{$f_2$} \\ \hline
$[-0.5,1.0]$&-7.62939453125e-6&-7.629452739132958e-6&16 \\
$[-0.25,1.5]$&-7.62939453125e-6&-7.629452739132958e-6&15 \\
$[-1.0,6.0]$&-3.814697265625e-6&-3.814711817567984e-6&18 \\
$[-1.5,100.0]$&49.25&2.010958004139294e-20&1 \\
$[-5.0,1000.0]$&497.5&4.318056675122884e-214&1 \\
\end{tabular}
\caption{Miejsca zerowe $f_1$ i $f_2$ obliczone za pomocą metody bisekcji.}
\label{table:3}
\end{table}

\begin{table}[h]
        \centering
        \footnotesize
\begin{tabular}{c
		|S[
        table-number-alignment = right,
		table-figures-integer  = 3,
		table-figures-decimal = 16,
		table-figures-exponent = 2
		]
		|S[
        table-number-alignment = right,
		table-figures-integer  = 2,
		table-figures-decimal = 16,
		table-figures-exponent = 3
		]|c|c}
$x_0$& {$r$} & {$f(r)$} & Liczba iteracji & Błąd \\ \hline
\multicolumn{5}{c}{$f_1$} \\ \hline
-1.0&0.9999922654776594&7.734552252003368e-6&5&0 \\
0.0&0.9999984358892101&1.5641120130194253e-6&4&0 \\
1.0&1.0&0.0&0&0 \\
2.0&0.9999999810061002&1.8993900008368314e-8&5&0 \\
5.0&0.9999996427095682&3.572904956339329e-7&54&0 \\
7.0&0.9999999484165362&5.15834650549607e-8&401&0 \\
8.0&{---}&{---}&{---}&1 \\
13.0&{---}&{---}&{---}&2 \\ \hline
\multicolumn{5}{c}{$f_2$} \\ \hline
-2.0&-1.425500682806244e-9&-1.425500684838296e-9&7&0 \\
-1.0&-3.0642493416461764e-7&-3.0642502806087233e-7&5&0 \\
0.0&0.0&0.0&0&0 \\
0.5&-3.0642493416461764e-7&-3.0642502806087233e-7&5&0 \\
1.0&{---}&{---}&{---}&2 \\
2.0&14.398662765680003&8.036415344217211e-6&10&0 \\
5.0&15.19428398343915&3.827247505782987e-6&9&0 \\
100.0&100.0&3.7200759760208363e-42&0&0 \\

\end{tabular}
\caption{Miejsca zerowe $f_1$ i $f_2$ obliczone za pomocą metody stycznych.}
\label{table:4}
\end{table}

\begin{table}[h]
        \centering
        \footnotesize
\begin{tabular}{c|c
		|S[
        table-number-alignment = right,
		table-figures-integer  = 3,
		table-figures-decimal = 16,
		table-figures-exponent = 2
		]
		|S[
        table-number-alignment = right,
		table-figures-integer  = 2,
		table-figures-decimal = 16,
		table-figures-exponent = 3
		]|c|c}
$x_0$&$x_1$& {$r$} & {$f(r)$} & Liczba iteracji & Błąd \\ \hline
\multicolumn{5}{c}{$f_1$} \\ \hline
-1.0&2.0&1.0000009310146594&-9.310142259355558e-7&7&0 \\
0.5&3.0&0.9999998801054126&1.1989459447470097e-7&6&0 \\
-3.0&4.0&0.9999924734799833&7.526548341019179e-6&1500&0 \\
-2.0&6.0&5.229263398675002&-0.9854368861925255&5&0 \\
10.0&100.0&{---}&{---}&{---}&1 \\ \hline
\multicolumn{5}{c}{$f_2$} \\ \hline
-1.0&0.5&3.201418966654486e-7&3.2014179417463104e-7&7&0 \\
-0.25&1.5&5.662892187393383e-7&5.662888980559498e-7&7&0 \\
2.0&6.0&14.386737398698989&8.12609044213971e-6&12&0 \\
10.0&20.0&20.00090808104888&4.118752554492817e-8&1&0 \\
-2.0&100.0&100.0&3.7200759760208363e-42&1&0 \\

\end{tabular}
\caption{Miejsca zerowe $f_1$ i $f_2$ obliczone za pomocą metody siecznych.}
\label{table:5}
\end{table}

\subsection{Wnioski}
Analiza wyników dla metody bisekcji przedstawionych w tabeli \ref{table:3} pozwala stwierdzić, że dla funkcji $f_1$ metoda ta jest zbieżna do faktycznego zera nawet dla bardzo dużych przedziałów, potrzebuje wtedy jednak odpowiednio większej liczby iteracji. Natomiast przy obliczaniu zer funkcji $f_2$ należy uważać na dobór przedziałów nawet stosując metodę bisekcji, gdyż funkcja ta osiąga zero w nieskończoności i wzięcie bardzo dużego przedziału początkowego może skutkować zakończeniem się obliczeń po jednej iteracji, gdyż wartość będzie dostatecznie bliska wartości zera, jednak bardzo odległa od faktycznego pierwiastka funkcji. \\
\linebreak
Wyniki uzyskane za pomocą metody Newtona prezentowane w tabeli \ref{table:4} pozwalają zauważyć że dla $f_1$ dla wartości nieco bardziej oddalonych od zera liczba iteracji pozwalająca znaleźć ten pierwiastek znacznie rośnie, aż w końcu metoda staje się rozbieżna (dla przybliżenia początkowego równego osiem po milionie iteracji nie znaleziono wartości dostatecznie bliskiej pierwiastkowi). Kolejnym niebezpieczeństwem jakie można zauważyć jest to, że w pewnym momencie funkcja $f_1$, bardzo wolno maleje, jest prawie stała, więc jej pochodna osiąga wartość bliską zeru i zastosowanie metody Newtona staje się niemożliwe. W przypadku funkcji $f_2$ pochodna zeruje się gdy $x_0 = 1$ i dla każdej wartości przybliżenia początkowego większej od jeden metoda nie zbiega do faktycznego zera funkcji, ale znajduje wartość dostatecznie bliską zeru odległą od miejsca zerowego z powodu granicy $f_2$ równej zero w nieskończoności. \\
\linebreak
\Cref{table:5} zawiera wyniki obliczeń wykonanych metodą siecznych. Dla funkcji $f_1$ dla wartości przybliżeń początkowych nie tak bliskich zeru możemy obserwować rozbieżność podobną jak w metodzie Newtona. Dziwić może wynik uzyskany dla przybliżeń $-2$ i $6$, jest to przykład, kiedy metoda nie znajduje wartości funkcji bliskiej zeru, ale w pewnym momencie zachodzi warunek $|x_1 - x_0| < delta$ i metoda kończy działanie. Wynika to z faktu, że różnica między wartościami funkcji $f_1$ w $-2$ i $6$ jest bardzo duża i kolejne przybliżenie wyznaczane jest bardzo blisko $6$, a przy kolejnych iteracjach ta wartość jest jeszcze pomniejszana. Dla funkcji $f_2$ analogicznie do metody Newtona, metoda siecznych dla odpowiednio odległych od pierwiastka przybliżeń początkowych nie znajduje faktycznego zera, ale punkty od niego oddalone ze względu na granicę funkcji. \\

\end{document}
